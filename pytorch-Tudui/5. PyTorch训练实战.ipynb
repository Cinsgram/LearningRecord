{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. PyTorch训练实战——完整训练套路**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面用 CIFAR 10 数据集来完成一个完整的分类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 准备数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter # tensorflow需要尽早导入\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset's Size: 50000\n",
      "Test Dataset's Size: 10000\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10('./data', train=True, \n",
    "                                          transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=False)\n",
    "test_data = torchvision.datasets.CIFAR10('./data', train=False, \n",
    "                                         transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=False)\n",
    "\n",
    "# 查看训练数据集、测试数据集分别有多少张图片\n",
    "print(\"Train Dataset's Size: {}\".format(len(train_data)))\n",
    "print(\"Test Dataset's Size: {}\".format(len(test_data)))\n",
    "# len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 DataLoader 来加载数据集，正确传递数据集对象\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2 搭建神经网络**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用的网络模型如下图所示：\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./image/3-10.png\" width=\"90%\"><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建神经网络\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10), \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试网络的正确性\n",
    "network = NeuralNetwork()\n",
    "input = torch.ones((64, 3, 32, 32))\n",
    "output = network(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3 利用网络进行训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建网络模型\n",
    "network = NeuralNetwork()\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# 学习率\n",
    "# lr = 0.01\n",
    "lr = 1e-2   # 1 × 10^(-2)\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------第 1 轮训练开始----------\n",
      "训练次数：100, Loss：2.288135051727295\n",
      "训练次数：200, Loss：2.285370349884033\n",
      "训练次数：300, Loss：2.250706195831299\n",
      "训练次数：400, Loss：2.169644594192505\n",
      "训练次数：500, Loss：2.0636801719665527\n",
      "训练次数：600, Loss：2.1239278316497803\n",
      "训练次数：700, Loss：2.056734085083008\n",
      "----------第 2 轮训练开始----------\n",
      "训练次数：800, Loss：1.889098048210144\n",
      "训练次数：900, Loss：1.9125136137008667\n",
      "训练次数：1000, Loss：1.857420802116394\n",
      "训练次数：1100, Loss：1.8069065809249878\n",
      "训练次数：1200, Loss：1.9366848468780518\n",
      "训练次数：1300, Loss：1.6871473789215088\n",
      "训练次数：1400, Loss：1.803779125213623\n",
      "训练次数：1500, Loss：1.8286163806915283\n",
      "----------第 3 轮训练开始----------\n",
      "训练次数：1600, Loss：1.755973219871521\n",
      "训练次数：1700, Loss：1.52785062789917\n",
      "训练次数：1800, Loss：1.7954740524291992\n",
      "训练次数：1900, Loss：1.9818954467773438\n",
      "训练次数：2000, Loss：1.5561673641204834\n",
      "训练次数：2100, Loss：1.4396220445632935\n",
      "训练次数：2200, Loss：1.653775930404663\n",
      "训练次数：2300, Loss：1.607715129852295\n",
      "----------第 4 轮训练开始----------\n",
      "训练次数：2400, Loss：1.5414866209030151\n",
      "训练次数：2500, Loss：1.5002042055130005\n",
      "训练次数：2600, Loss：1.5846762657165527\n",
      "训练次数：2700, Loss：1.4671354293823242\n",
      "训练次数：2800, Loss：1.4748287200927734\n",
      "训练次数：2900, Loss：1.494982361793518\n",
      "训练次数：3000, Loss：1.4524149894714355\n",
      "训练次数：3100, Loss：1.6397075653076172\n",
      "----------第 5 轮训练开始----------\n",
      "训练次数：3200, Loss：1.4066022634506226\n",
      "训练次数：3300, Loss：1.3977487087249756\n",
      "训练次数：3400, Loss：1.3465983867645264\n",
      "训练次数：3500, Loss：1.4139617681503296\n",
      "训练次数：3600, Loss：1.3739750385284424\n",
      "训练次数：3700, Loss：1.4834637641906738\n",
      "训练次数：3800, Loss：1.0629242658615112\n",
      "训练次数：3900, Loss：1.4132100343704224\n",
      "----------第 6 轮训练开始----------\n",
      "训练次数：4000, Loss：1.4092259407043457\n",
      "训练次数：4100, Loss：1.3192315101623535\n",
      "训练次数：4200, Loss：1.3410979509353638\n",
      "训练次数：4300, Loss：1.6040992736816406\n",
      "训练次数：4400, Loss：1.3810776472091675\n",
      "训练次数：4500, Loss：1.3494943380355835\n",
      "训练次数：4600, Loss：1.0352643728256226\n",
      "----------第 7 轮训练开始----------\n",
      "训练次数：4700, Loss：1.3551405668258667\n",
      "训练次数：4800, Loss：1.4126887321472168\n",
      "训练次数：4900, Loss：1.1328765153884888\n",
      "训练次数：5000, Loss：1.51873779296875\n",
      "训练次数：5100, Loss：1.2694385051727295\n",
      "训练次数：5200, Loss：1.409751534461975\n",
      "训练次数：5300, Loss：1.3991769552230835\n",
      "训练次数：5400, Loss：1.5842045545578003\n",
      "----------第 8 轮训练开始----------\n",
      "训练次数：5500, Loss：1.4129174947738647\n",
      "训练次数：5600, Loss：1.197293758392334\n",
      "训练次数：5700, Loss：1.20614755153656\n",
      "训练次数：5800, Loss：1.0271153450012207\n",
      "训练次数：5900, Loss：1.1897614002227783\n",
      "训练次数：6000, Loss：1.1867105960845947\n",
      "训练次数：6100, Loss：1.2765735387802124\n",
      "训练次数：6200, Loss：1.2484939098358154\n",
      "----------第 9 轮训练开始----------\n",
      "训练次数：6300, Loss：1.2716814279556274\n",
      "训练次数：6400, Loss：1.4013742208480835\n",
      "训练次数：6500, Loss：1.3672314882278442\n",
      "训练次数：6600, Loss：1.2279822826385498\n",
      "训练次数：6700, Loss：1.0909230709075928\n",
      "训练次数：6800, Loss：1.2195887565612793\n",
      "训练次数：6900, Loss：1.0249162912368774\n",
      "训练次数：7000, Loss：1.1258621215820312\n",
      "----------第 10 轮训练开始----------\n",
      "训练次数：7100, Loss：1.0151633024215698\n",
      "训练次数：7200, Loss：1.1297438144683838\n",
      "训练次数：7300, Loss：1.3010907173156738\n",
      "训练次数：7400, Loss：1.3036545515060425\n",
      "训练次数：7500, Loss：1.0887893438339233\n",
      "训练次数：7600, Loss：0.8696722984313965\n",
      "训练次数：7700, Loss：1.222790241241455\n",
      "训练次数：7800, Loss：1.215111494064331\n"
     ]
    }
   ],
   "source": [
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"----------第 {} 轮训练开始----------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = network(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # 优化器调优\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_step += 1\n",
    "        # 训练步骤逢百的时候才打印\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# item的作用\n",
    "import torch\n",
    "a = torch.tensor(5)\n",
    "print(a)\n",
    "print(a.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.4 评估训练情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------第 1 轮训练开始----------\n",
      "整体测试集上的loss: 873.3963012695312\n",
      "----------第 2 轮训练开始----------\n",
      "整体测试集上的loss: 876.9664916992188\n",
      "----------第 3 轮训练开始----------\n",
      "整体测试集上的loss: 924.1622314453125\n",
      "----------第 4 轮训练开始----------\n",
      "整体测试集上的loss: 733.2106323242188\n",
      "----------第 5 轮训练开始----------\n",
      "整体测试集上的loss: 866.1978759765625\n",
      "----------第 6 轮训练开始----------\n",
      "整体测试集上的loss: 790.5870361328125\n",
      "----------第 7 轮训练开始----------\n",
      "整体测试集上的loss: 696.77197265625\n",
      "----------第 8 轮训练开始----------\n",
      "整体测试集上的loss: 696.7969970703125\n",
      "----------第 9 轮训练开始----------\n",
      "整体测试集上的loss: 675.2025756835938\n",
      "----------第 10 轮训练开始----------\n",
      "整体测试集上的loss: 654.0797729492188\n"
     ]
    }
   ],
   "source": [
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"----------第 {} 轮训练开始----------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = network(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # 优化器调优\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_step += 1\n",
    "        # 训练步骤逢百的时候才打印\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))\n",
    "        # print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))\n",
    "        \n",
    "    # 测试步骤开始（每轮训练后都查看在测试数据集上的loss情况）\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():   # 没有梯度计算，节约内存\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            outputs = network(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss += loss\n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.5 tensorboard查看训练情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------第 1 轮训练开始----------\n",
      "训练次数：100, Loss：1.004499912261963\n",
      "训练次数：200, Loss：1.3714478015899658\n",
      "训练次数：300, Loss：1.2910605669021606\n",
      "训练次数：400, Loss：1.1755789518356323\n",
      "训练次数：500, Loss：1.2127759456634521\n",
      "训练次数：600, Loss：1.3611642122268677\n",
      "训练次数：700, Loss：0.9830293655395508\n",
      "整体测试集上的loss: 212.3978179693222\n",
      "----------第 2 轮训练开始----------\n",
      "训练次数：800, Loss：1.01309335231781\n",
      "训练次数：900, Loss：1.2425463199615479\n",
      "训练次数：1000, Loss：1.0553724765777588\n",
      "训练次数：1100, Loss：0.9625992774963379\n",
      "训练次数：1200, Loss：1.0058939456939697\n",
      "训练次数：1300, Loss：0.9937781095504761\n",
      "训练次数：1400, Loss：1.1345794200897217\n",
      "训练次数：1500, Loss：1.0009208917617798\n",
      "整体测试集上的loss: 190.81010353565216\n",
      "----------第 3 轮训练开始----------\n",
      "训练次数：1600, Loss：1.0100057125091553\n",
      "训练次数：1700, Loss：1.1619864702224731\n",
      "训练次数：1800, Loss：1.0821768045425415\n",
      "训练次数：1900, Loss：1.051303744316101\n",
      "训练次数：2000, Loss：0.92399662733078\n",
      "训练次数：2100, Loss：1.0712974071502686\n",
      "训练次数：2200, Loss：1.1239312887191772\n",
      "训练次数：2300, Loss：1.1094300746917725\n",
      "整体测试集上的loss: 173.9824411869049\n",
      "----------第 4 轮训练开始----------\n",
      "训练次数：2400, Loss：1.0728368759155273\n",
      "训练次数：2500, Loss：1.0893083810806274\n",
      "训练次数：2600, Loss：0.9061659574508667\n",
      "训练次数：2700, Loss：0.8188464045524597\n",
      "训练次数：2800, Loss：1.0048748254776\n",
      "训练次数：2900, Loss：1.1096365451812744\n",
      "训练次数：3000, Loss：0.8909847736358643\n",
      "训练次数：3100, Loss：0.9316242337226868\n",
      "整体测试集上的loss: 193.52192908525467\n",
      "----------第 5 轮训练开始----------\n",
      "训练次数：3200, Loss：0.9594253897666931\n",
      "训练次数：3300, Loss：1.0370121002197266\n",
      "训练次数：3400, Loss：0.946592390537262\n",
      "训练次数：3500, Loss：0.947799026966095\n",
      "训练次数：3600, Loss：1.1427215337753296\n",
      "训练次数：3700, Loss：0.9180985689163208\n",
      "训练次数：3800, Loss：1.186365008354187\n",
      "训练次数：3900, Loss：0.8612458109855652\n",
      "整体测试集上的loss: 176.24396353960037\n",
      "----------第 6 轮训练开始----------\n",
      "训练次数：4000, Loss：0.9872498512268066\n",
      "训练次数：4100, Loss：0.8390129804611206\n",
      "训练次数：4200, Loss：1.1835918426513672\n",
      "训练次数：4300, Loss：1.028704047203064\n",
      "训练次数：4400, Loss：1.2521109580993652\n",
      "训练次数：4500, Loss：1.121653437614441\n",
      "训练次数：4600, Loss：0.9140222072601318\n",
      "整体测试集上的loss: 172.88125002384186\n",
      "----------第 7 轮训练开始----------\n",
      "训练次数：4700, Loss：0.9117640852928162\n",
      "训练次数：4800, Loss：1.0772383213043213\n",
      "训练次数：4900, Loss：1.0030272006988525\n",
      "训练次数：5000, Loss：0.6518337726593018\n",
      "训练次数：5100, Loss：0.7373448610305786\n",
      "训练次数：5200, Loss：1.192481279373169\n",
      "训练次数：5300, Loss：0.7862146496772766\n",
      "训练次数：5400, Loss：1.0654411315917969\n",
      "整体测试集上的loss: 161.7947599887848\n",
      "----------第 8 轮训练开始----------\n",
      "训练次数：5500, Loss：1.1826465129852295\n",
      "训练次数：5600, Loss：0.7600317001342773\n",
      "训练次数：5700, Loss：0.787023663520813\n",
      "训练次数：5800, Loss：1.287665605545044\n",
      "训练次数：5900, Loss：0.6469299793243408\n",
      "训练次数：6000, Loss：1.0969666242599487\n",
      "训练次数：6100, Loss：0.7960755228996277\n",
      "训练次数：6200, Loss：1.0606106519699097\n",
      "整体测试集上的loss: 185.4983188509941\n",
      "----------第 9 轮训练开始----------\n",
      "训练次数：6300, Loss：0.9254653453826904\n",
      "训练次数：6400, Loss：1.0907540321350098\n",
      "训练次数：6500, Loss：0.8287320733070374\n",
      "训练次数：6600, Loss：1.1557058095932007\n",
      "训练次数：6700, Loss：0.7542644143104553\n",
      "训练次数：6800, Loss：1.1825851202011108\n",
      "训练次数：6900, Loss：0.9906306862831116\n",
      "训练次数：7000, Loss：0.7095465660095215\n",
      "整体测试集上的loss: 167.34764844179153\n",
      "----------第 10 轮训练开始----------\n",
      "训练次数：7100, Loss：1.0075386762619019\n",
      "训练次数：7200, Loss：0.841170608997345\n",
      "训练次数：7300, Loss：0.7861294150352478\n",
      "训练次数：7400, Loss：0.7781770825386047\n",
      "训练次数：7500, Loss：0.9664531350135803\n",
      "训练次数：7600, Loss：0.8183588981628418\n",
      "训练次数：7700, Loss：0.8021371960639954\n",
      "训练次数：7800, Loss：0.7448807954788208\n",
      "整体测试集上的loss: 186.55233347415924\n"
     ]
    }
   ],
   "source": [
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter('./log')\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"----------第 {} 轮训练开始----------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = network(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # 优化器调优\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_step += 1\n",
    "        # 训练步骤逢百的时候才打印\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar('Train_Loss', loss.item(), total_train_step)\n",
    "        # print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))\n",
    "        # writer.add_scalar('Train_Loss', loss.item(), total_train_step)\n",
    "        \n",
    "    # 测试步骤开始（每轮训练后都查看在测试数据集上的loss情况）\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():   # 没有梯度计算，节约内存\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            outputs = network(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss += loss.item()\n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))\n",
    "    writer.add_scalar(\"Test_Loss\", total_test_loss, total_test_step)\n",
    "    total_test_step += 1\n",
    "    \n",
    "    # 保存每一轮训练的模型\n",
    "    torch.save(network, \"network_{}.path\".format(i))\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.6 查看分类正确率**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "outputs = torch.tensor([[0.1,0.2],\n",
    "                        [0.05,0.4]])\n",
    "print(outputs.argmax(0))    # 竖着看，最大值的索引\n",
    "print(outputs.argmax(1))    # 横着看，最大值的索引\n",
    "\n",
    "preds = outputs.argmax(0)\n",
    "targets = torch.tensor([0,1])\n",
    "print((preds == targets).sum()) # 对应位置相等的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------第 1 轮训练开始----------\n",
      "训练次数：100, Loss：0.5346081852912903\n",
      "训练次数：200, Loss：0.5090819001197815\n",
      "训练次数：300, Loss：0.5422479510307312\n",
      "训练次数：400, Loss：0.7091524004936218\n",
      "训练次数：500, Loss：0.4985291659832001\n",
      "训练次数：600, Loss：0.5808225870132446\n",
      "训练次数：700, Loss：0.44398781657218933\n",
      "整体测试集上的loss: 407.5290805399418\n",
      "整体测试集上的accuracy: 0.00026000000070780516\n",
      "----------第 2 轮训练开始----------\n",
      "训练次数：800, Loss：0.47275006771087646\n",
      "训练次数：900, Loss：0.74887615442276\n",
      "训练次数：1000, Loss：0.6071299314498901\n",
      "训练次数：1100, Loss：0.6862225532531738\n",
      "训练次数：1200, Loss：0.7903950214385986\n",
      "训练次数：1300, Loss：0.4546363353729248\n",
      "训练次数：1400, Loss：0.6451870203018188\n",
      "训练次数：1500, Loss：0.5209717750549316\n",
      "整体测试集上的loss: 376.0288095623255\n",
      "整体测试集上的accuracy: 0.00026000000070780516\n",
      "----------第 3 轮训练开始----------\n",
      "训练次数：1600, Loss：0.32872894406318665\n",
      "训练次数：1700, Loss：0.2941220700740814\n",
      "训练次数：1800, Loss：0.2592940330505371\n",
      "训练次数：1900, Loss：0.44594305753707886\n",
      "训练次数：2000, Loss：0.29770275950431824\n",
      "训练次数：2100, Loss：0.7144792079925537\n",
      "训练次数：2200, Loss：0.5121883749961853\n",
      "训练次数：2300, Loss：0.3758026957511902\n",
      "整体测试集上的loss: 395.68653443455696\n",
      "整体测试集上的accuracy: 0.00026000000070780516\n",
      "----------第 4 轮训练开始----------\n",
      "训练次数：2400, Loss：0.306350976228714\n",
      "训练次数：2500, Loss：0.4713774025440216\n",
      "训练次数：2600, Loss：0.4898184537887573\n",
      "训练次数：2700, Loss：0.5730881690979004\n",
      "训练次数：2800, Loss：0.5361673831939697\n",
      "训练次数：2900, Loss：0.2563300132751465\n",
      "训练次数：3000, Loss：0.5213015079498291\n",
      "训练次数：3100, Loss：0.6687918901443481\n",
      "整体测试集上的loss: 412.6176188737154\n",
      "整体测试集上的accuracy: 0.0003000000142492354\n",
      "----------第 5 轮训练开始----------\n",
      "训练次数：3200, Loss：0.44785821437835693\n",
      "训练次数：3300, Loss：0.5231873989105225\n",
      "训练次数：3400, Loss：0.5434172749519348\n",
      "训练次数：3500, Loss：0.35727664828300476\n",
      "训练次数：3600, Loss：0.40915194153785706\n",
      "训练次数：3700, Loss：0.305489718914032\n",
      "训练次数：3800, Loss：0.4243663251399994\n",
      "训练次数：3900, Loss：0.4791753888130188\n",
      "整体测试集上的loss: 376.3336865156889\n",
      "整体测试集上的accuracy: 0.00026000000070780516\n",
      "----------第 6 轮训练开始----------\n",
      "训练次数：4000, Loss：0.37365588545799255\n",
      "训练次数：4100, Loss：0.4819070100784302\n",
      "训练次数：4200, Loss：0.29221227765083313\n",
      "训练次数：4300, Loss：0.45218560099601746\n",
      "训练次数：4400, Loss：0.5406009554862976\n",
      "训练次数：4500, Loss：0.5259199142456055\n",
      "训练次数：4600, Loss：0.4214931130409241\n",
      "整体测试集上的loss: 555.7533032596111\n",
      "整体测试集上的accuracy: 0.00023999999393709004\n",
      "----------第 7 轮训练开始----------\n",
      "训练次数：4700, Loss：0.5270240306854248\n",
      "训练次数：4800, Loss：0.7252525091171265\n",
      "训练次数：4900, Loss：0.43234574794769287\n",
      "训练次数：5000, Loss：0.37680450081825256\n",
      "训练次数：5100, Loss：0.5058954954147339\n",
      "训练次数：5200, Loss：0.5470982193946838\n",
      "训练次数：5300, Loss：0.35919564962387085\n",
      "训练次数：5400, Loss：0.5724364519119263\n",
      "整体测试集上的loss: 351.64604534208775\n",
      "整体测试集上的accuracy: 0.0003000000142492354\n",
      "----------第 8 轮训练开始----------\n",
      "训练次数：5500, Loss：0.5726699829101562\n",
      "训练次数：5600, Loss：0.29924508929252625\n",
      "训练次数：5700, Loss：0.4605614244937897\n",
      "训练次数：5800, Loss：0.589216411113739\n",
      "训练次数：5900, Loss：0.4486097991466522\n",
      "训练次数：6000, Loss：0.5146834850311279\n",
      "训练次数：6100, Loss：0.5547563433647156\n",
      "训练次数：6200, Loss：0.678767740726471\n",
      "整体测试集上的loss: 386.8906899392605\n",
      "整体测试集上的accuracy: 0.00026000000070780516\n",
      "----------第 9 轮训练开始----------\n",
      "训练次数：6300, Loss：0.3344690501689911\n",
      "训练次数：6400, Loss：0.594308614730835\n",
      "训练次数：6500, Loss：0.340475857257843\n",
      "训练次数：6600, Loss：0.48898425698280334\n",
      "训练次数：6700, Loss：0.45945245027542114\n",
      "训练次数：6800, Loss：0.5361608266830444\n",
      "训练次数：6900, Loss：0.4509144425392151\n",
      "训练次数：7000, Loss：0.5674741864204407\n",
      "整体测试集上的loss: 300.3952583819628\n",
      "整体测试集上的accuracy: 0.00026000000070780516\n",
      "----------第 10 轮训练开始----------\n",
      "训练次数：7100, Loss：0.41381117701530457\n",
      "训练次数：7200, Loss：0.28106415271759033\n",
      "训练次数：7300, Loss：0.4972143769264221\n",
      "训练次数：7400, Loss：0.3751281499862671\n",
      "训练次数：7500, Loss：0.35303136706352234\n",
      "训练次数：7600, Loss：0.4222612977027893\n",
      "训练次数：7700, Loss：0.36235311627388\n",
      "训练次数：7800, Loss：0.6554174423217773\n",
      "整体测试集上的loss: 457.8782811462879\n",
      "整体测试集上的accuracy: 0.00023999999393709004\n"
     ]
    }
   ],
   "source": [
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter('./log')\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"----------第 {} 轮训练开始----------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = network(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # 优化器调优\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_step += 1\n",
    "        # 训练步骤逢百的时候才打印\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar('Train_Loss', loss.item(), total_train_step)\n",
    "        # print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))\n",
    "        # writer.add_scalar('Train_Loss', loss.item(), total_train_step)\n",
    "        \n",
    "    # 测试步骤开始（每轮训练后都查看在测试数据集上的loss情况）\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():   # 没有梯度计算，节约内存\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            outputs = network(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss += loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy += accuracy\n",
    "    \n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的accuracy: {}\".format(total_accuracy/len(test_data)))\n",
    "    \n",
    "    writer.add_scalar(\"Test_Accuracy\", total_accuracy/len(test_data), total_test_step)\n",
    "    writer.add_scalar(\"Test_Loss\", total_test_loss, total_test_step)\n",
    "    total_test_step += 1\n",
    "    \n",
    "    # 保存每一轮训练的模型\n",
    "    torch.save(network, \"./model/network_{}.path\".format(i))\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.7 特殊层的作用**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习中，`model.train()`和`model.eval()`是两个非常重要的方法，它们在 PyTorch 框架中用于切换模型的行为模式，确保在不同阶段（训练与评估）中模型能正确地表现。\n",
    "\n",
    "1. `model.train()`\n",
    "\n",
    "`model.train()`方法将模型设置为训练模式。可以认为这就像是告诉模型：“现在是练习时间，要尽可能多地学习和适应。” 在训练模式下，模型会激活所有设计用于训练的特性，如：\n",
    "\n",
    "- **批量归一化（Batch Normalization）**：这一层会在每个训练批次中动态调整数据的均值和标准差，帮助模型更好地学习。\n",
    "- **Dropout**：这是一种防止模型过拟合的技术，通过随机关闭（即“丢弃”）网络中的部分神经元来减少模型对训练数据的依赖。\n",
    "\n",
    "2. `model.eval()`\n",
    "\n",
    "`model.eval()`方法将模型设置为评估模式。这就像是告诉模型：“表演时间到了，需要表现出你的最佳状态。” 在评估模式下，模型会关闭训练时使用的特定层的某些功能：\n",
    "\n",
    "- **批量归一化**：不再更新数据的统计信息，而是使用训练时已经学习到的均值和标准差。\n",
    "- **Dropout**：完全关闭，确保所有神经元都参与到模型的运算中，以便模型可以利用其全部能力来进行预测。\n",
    "\n",
    "这两个模式的切换对于训练一个可靠的模型至关重要。如果在训练阶段不使用`model.train()`，模型可能就无法正确使用Dropout等技术，从而无法有效防止过拟合。同样，如果在评估或测试阶段不使用`model.eval()`，模型的Dropout层仍会随机关闭一部分神经元，导致输出结果不稳定，不能真实反映模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------第 1 轮训练开始----------\n",
      "训练次数：100, Loss：0.8041135668754578\n",
      "训练次数：200, Loss：0.6040640473365784\n",
      "训练次数：300, Loss：0.5956678986549377\n",
      "训练次数：400, Loss：0.739458441734314\n",
      "训练次数：500, Loss：0.8982022404670715\n",
      "训练次数：600, Loss：0.8687314391136169\n",
      "训练次数：700, Loss：0.6455435752868652\n",
      "整体测试集上的loss: 162.23805141448975\n",
      "整体测试集上的accuracy: 0.6514000296592712\n",
      "----------第 2 轮训练开始----------\n",
      "训练次数：800, Loss：0.7926114797592163\n",
      "训练次数：900, Loss：0.8763909935951233\n",
      "训练次数：1000, Loss：1.001367211341858\n",
      "训练次数：1100, Loss：0.5709820985794067\n",
      "训练次数：1200, Loss：1.067786455154419\n",
      "训练次数：1300, Loss：0.7595174312591553\n",
      "训练次数：1400, Loss：0.7987149953842163\n",
      "训练次数：1500, Loss：0.6851078867912292\n",
      "整体测试集上的loss: 166.89498454332352\n",
      "整体测试集上的accuracy: 0.635699987411499\n",
      "----------第 3 轮训练开始----------\n",
      "训练次数：1600, Loss：0.7969492673873901\n",
      "训练次数：1700, Loss：0.52077317237854\n",
      "训练次数：1800, Loss：0.7486023902893066\n",
      "训练次数：1900, Loss：0.7300198674201965\n",
      "训练次数：2000, Loss：0.8928712010383606\n",
      "训练次数：2100, Loss：0.644980788230896\n",
      "训练次数：2200, Loss：1.1257914304733276\n",
      "训练次数：2300, Loss：0.6445086002349854\n",
      "整体测试集上的loss: 213.21148562431335\n",
      "整体测试集上的accuracy: 0.5694000124931335\n",
      "----------第 4 轮训练开始----------\n",
      "训练次数：2400, Loss：0.74176025390625\n",
      "训练次数：2500, Loss：0.7664031982421875\n",
      "训练次数：2600, Loss：0.7824254631996155\n",
      "训练次数：2700, Loss：0.7672637104988098\n",
      "训练次数：2800, Loss：0.6724762916564941\n",
      "训练次数：2900, Loss：0.7739167809486389\n",
      "训练次数：3000, Loss：0.5120349526405334\n",
      "训练次数：3100, Loss：0.8515718579292297\n",
      "整体测试集上的loss: 176.50934290885925\n",
      "整体测试集上的accuracy: 0.6241000294685364\n",
      "----------第 5 轮训练开始----------\n",
      "训练次数：3200, Loss：0.5286877155303955\n",
      "训练次数：3300, Loss：0.9131481051445007\n",
      "训练次数：3400, Loss：0.7362421751022339\n",
      "训练次数：3500, Loss：0.7692256569862366\n",
      "训练次数：3600, Loss：0.8782521486282349\n",
      "训练次数：3700, Loss：0.8199642300605774\n",
      "训练次数：3800, Loss：0.772999107837677\n",
      "训练次数：3900, Loss：0.8017358183860779\n",
      "整体测试集上的loss: 162.6144026517868\n",
      "整体测试集上的accuracy: 0.6549999713897705\n",
      "----------第 6 轮训练开始----------\n",
      "训练次数：4000, Loss：0.8370603919029236\n",
      "训练次数：4100, Loss：0.7260438203811646\n",
      "训练次数：4200, Loss：0.7449522018432617\n",
      "训练次数：4300, Loss：0.6608306169509888\n",
      "训练次数：4400, Loss：0.5996816158294678\n",
      "训练次数：4500, Loss：0.5170162916183472\n",
      "训练次数：4600, Loss：0.6754004955291748\n",
      "整体测试集上的loss: 187.8229728937149\n",
      "整体测试集上的accuracy: 0.6274999976158142\n",
      "----------第 7 轮训练开始----------\n",
      "训练次数：4700, Loss：0.6818689107894897\n",
      "训练次数：4800, Loss：0.7650101184844971\n",
      "训练次数：4900, Loss：0.8795551061630249\n",
      "训练次数：5000, Loss：0.7796899676322937\n",
      "训练次数：5100, Loss：0.5398890376091003\n",
      "训练次数：5200, Loss：0.6961351037025452\n",
      "训练次数：5300, Loss：0.9585146307945251\n",
      "训练次数：5400, Loss：0.7238786220550537\n",
      "整体测试集上的loss: 159.2663615345955\n",
      "整体测试集上的accuracy: 0.6690999865531921\n",
      "----------第 8 轮训练开始----------\n",
      "训练次数：5500, Loss：0.543254017829895\n",
      "训练次数：5600, Loss：0.6282196640968323\n",
      "训练次数：5700, Loss：0.7533558011054993\n",
      "训练次数：5800, Loss：0.8966903686523438\n",
      "训练次数：5900, Loss：0.7840505838394165\n",
      "训练次数：6000, Loss：0.7339367270469666\n",
      "训练次数：6100, Loss：0.9143748879432678\n",
      "训练次数：6200, Loss：0.773175835609436\n",
      "整体测试集上的loss: 157.9066662788391\n",
      "整体测试集上的accuracy: 0.6669999957084656\n",
      "----------第 9 轮训练开始----------\n",
      "训练次数：6300, Loss：0.8131414651870728\n",
      "训练次数：6400, Loss：0.412451833486557\n",
      "训练次数：6500, Loss：0.7557477355003357\n",
      "训练次数：6600, Loss：0.6627057194709778\n",
      "训练次数：6700, Loss：0.8143982291221619\n",
      "训练次数：6800, Loss：1.130519151687622\n",
      "训练次数：6900, Loss：0.8138473629951477\n",
      "训练次数：7000, Loss：0.7800171375274658\n",
      "整体测试集上的loss: 169.87730932235718\n",
      "整体测试集上的accuracy: 0.6531999707221985\n",
      "----------第 10 轮训练开始----------\n",
      "训练次数：7100, Loss：0.5297341346740723\n",
      "训练次数：7200, Loss：0.6720685958862305\n",
      "训练次数：7300, Loss：0.7284762859344482\n",
      "训练次数：7400, Loss：0.6795467138290405\n",
      "训练次数：7500, Loss：0.7048993110656738\n",
      "训练次数：7600, Loss：0.5365629196166992\n",
      "训练次数：7700, Loss：0.7496657967567444\n",
      "训练次数：7800, Loss：0.7771860957145691\n",
      "整体测试集上的loss: 183.540321290493\n",
      "整体测试集上的accuracy: 0.6270999908447266\n"
     ]
    }
   ],
   "source": [
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter('./log')\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"----------第 {} 轮训练开始----------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    network.train()\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = network(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # 优化器调优\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_step += 1\n",
    "        # 训练步骤逢百的时候才打印\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar('Train_Loss', loss.item(), total_train_step)\n",
    "        # print(\"训练次数：{}, Loss：{}\".format(total_train_step, loss.item()))\n",
    "        # writer.add_scalar('Train_Loss', loss.item(), total_train_step)\n",
    "        \n",
    "    # 测试步骤开始（每轮训练后都查看在测试数据集上的loss情况）\n",
    "    network.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():   # 没有梯度计算，节约内存\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            outputs = network(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss += loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy += accuracy\n",
    "    \n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的accuracy: {}\".format(total_accuracy/len(test_data)))\n",
    "    \n",
    "    writer.add_scalar(\"Test_Accuracy\", total_accuracy/len(test_data), total_test_step)\n",
    "    writer.add_scalar(\"Test_Loss\", total_test_loss, total_test_step)\n",
    "    total_test_step += 1\n",
    "    \n",
    "    # 保存每一轮训练的模型\n",
    "    torch.save(network, \"./model/network_{}.path\".format(i))\n",
    "    \n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
